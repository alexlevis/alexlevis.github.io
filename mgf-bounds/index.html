<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>MGFs, power series, and pushing the expectation through - Alex Levis</title><meta name="Description" content="Welcome!"><meta property="og:url" content="https://alexlevis.github.io/mgf-bounds/">
  <meta property="og:site_name" content="Alex Levis">
  <meta property="og:title" content="MGFs, power series, and pushing the expectation through">
  <meta property="og:description" content="I got stuck on what I thought was a simple point while working through a stats textbook! I figured it out, I think, but was this the most straightforward path to understanding? You tell me! In this note, we explore some oft-used facts about moment-generating functions, and explain a connection with tail and concentration inequalities.
Overview and my confusion I am currently reading through Martin Wainwright’s High-dimensional statistics: A non-asymptotic viewpoint, to fill some gaps in my stat theory knowledge.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2022-08-05T00:00:00-05:00">
    <meta property="article:modified_time" content="2022-08-05T00:00:00-05:00">
    <meta property="og:image" content="https://alexlevis.github.io/logo.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://alexlevis.github.io/logo.png">
  <meta name="twitter:title" content="MGFs, power series, and pushing the expectation through">
  <meta name="twitter:description" content="I got stuck on what I thought was a simple point while working through a stats textbook! I figured it out, I think, but was this the most straightforward path to understanding? You tell me! In this note, we explore some oft-used facts about moment-generating functions, and explain a connection with tail and concentration inequalities.
Overview and my confusion I am currently reading through Martin Wainwright’s High-dimensional statistics: A non-asymptotic viewpoint, to fill some gaps in my stat theory knowledge.">
<meta name="application-name" content="alexlevis.github.io">
<meta name="apple-mobile-web-app-title" content="alexlevis.github.io"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://alexlevis.github.io/mgf-bounds/" /><link rel="next" href="https://alexlevis.github.io/instrument-precision/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "MGFs, power series, and pushing the expectation through",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/alexlevis.github.io\/mgf-bounds\/"
        },"genre": "posts","wordcount":  2090 ,
        "url": "https:\/\/alexlevis.github.io\/mgf-bounds\/","datePublished": "2022-08-05T00:00:00-05:00","dateModified": "2022-08-05T00:00:00-05:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Alex Levis"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Alex Levis">Alex Levis</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/about/"><i class="fas fa-user"></i> About </a><a class="menu-item" href="/posts/"><i class="fas fa-pen-square"></i> Posts </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Alex Levis">Alex Levis</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/about/" title=""><i class="fas fa-user"></i>About</a><a class="menu-item" href="/posts/" title=""><i class="fas fa-pen-square"></i>Posts</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">MGFs, power series, and pushing the expectation through</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Alex Levis</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2022-08-05">2022-08-05</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;2090 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;10 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#overview-and-my-confusion">Overview and my confusion</a></li>
    <li><a href="#facts-about-moment-generating-functions">Facts about moment generating functions</a></li>
    <li><a href="#relation-to-sub-exponential-distributions">Relation to sub-exponential distributions</a></li>
    <li><a href="#control-of-the-moments-and-bernstein-s-condition">Control of the moments and Bernstein&rsquo;s condition</a></li>
    <li><a href="#bonus-a-direct-analysis-of-the-bernstein-condition">BONUS: A direct analysis of the Bernstein condition</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>I got stuck on what I thought was a simple point while working through
a stats textbook! I figured it out, I think, but was this the most
straightforward path to understanding?  You tell me! In this note, we
explore some oft-used facts about moment-generating functions, and
explain a connection with tail and concentration inequalities.</p>
<h2 id="overview-and-my-confusion">Overview and my confusion</h2>
<p>I am currently reading through <a href="https://people.eecs.berkeley.edu/~wainwrig/" target="_blank" rel="noopener noreffer ">Martin Wainwright</a>&rsquo;s <em><a href="https://www.amazon.com/High-Dimensional-Statistics-Non-Asymptotic-Statistical-Probabilistic-ebook/dp/B07N46XF8B" target="_blank" rel="noopener noreffer ">High-dimensional
statistics: A non-asymptotic viewpoint</a></em>, to fill some gaps in my stat
theory knowledge. While I&rsquo;m only partway through, I can definitely
already recommend this book for those wanting to get familiar with
some of the modern theoretical machinery needed to validate
statistical methods that we use on difficult problems!</p>
<p>The book starts off relatively lightly in Chapter 2 with an overview
of fundamental tail and concentration bounds. A simple but powerful
idea is that of <a href="https://en.wikipedia.org/wiki/Chernoff_bound" target="_blank" rel="noopener noreffer ">Chernoff bounding</a>, which combines the moment
generating function of a random variable (when it exists), and
<a href="https://en.wikipedia.org/wiki/Markov%27s_inequality" target="_blank" rel="noopener noreffer ">Markov&rsquo;s inequality</a> to tightly bound tail probabilities. In reading
through this chapter, one quickly comes across the <em>sub-exponential</em>
class of distributions: a random variable \(X\) is sub-exponential if
\(\mathbb{E}(|X|) &lt; \infty\) and there exist constants \(\nu &gt; 0\) and
\(\alpha \in [0,\infty)\) such that \[\mathbb{E}(e^{t (X-\mu)}) \leq
e^{\frac{\nu^2 t^2}{2}}, \text{for all } t \in
\left(-\frac{1}{\alpha}, \frac{1}{\alpha}\right),\] where \(\mu
\coloneqq \mathbb{E}(X)\) and we use the convention that \(\frac{1}{0} =
\infty\).</p>
<p>Following this introduction, we are then exposed to a sufficient
condition for \(X\) to be sub-exponential, the so-called <em>Bernstein
condition</em>. In particular, \(X\) is said to be $b$-Bernstein, for some
\(b &gt; 0\), if \(\mathbb{E}(|X|^2) &lt; \infty\), and letting \(\mu \coloneqq
\mathbb{E}(X)\), \(\sigma^2 \coloneqq \mathrm{Var}(X)\), it holds that
\[\left|\mathbb{E}[(X - \mu)^k]\right| \leq \frac{1}{2}k! \sigma^2
b^{k-2}, \text{ for all } k \in \mathbb{N} \setminus \{1\}.\] In
proving that this condition implies that \(X\) is sub-exponential, the
author employs the &ldquo;<a href="https://en.wikipedia.org/wiki/Power_series" target="_blank" rel="noopener noreffer ">power series</a> decomposition&rdquo; \(\mathbb{E}(e^{t(X-
\mu)}) = \sum_{n = 0}^\infty \frac{t^n}{n!}  \mathbb{E}[(X-\mu)^n]\),
for \(t\) non-zero but sufficiently small. That said, I couldn&rsquo;t find
anywhere in the book where this equality was justified.</p>
<p>At first glance, this equality might seem obvious, as \(e^{z} =
\sum_{n=0}^\infty \frac{z^n}{n!}\) for all \(z \in \mathbb{R}\), so one
should just be able to push the expectation through this power series
representation. But usually this sort of statement is justified by the
dominated convergence theorem (DCT): if \(Y_n \to Y\), and the sequence
\(Y_n\) is bounded by \(Z \in L_1\), i.e., \(|Y_n| \leq Z\) for all \(n \in
\mathbb{N}\) and \(\mathbb{E}(Z) &lt; \infty\), then \(\mathbb{E}(|Y_n|),
\mathbb{E}(|Y|) &lt; \infty\) and \(\mathbb{E}(Y) = \lim_{n \to \infty}
\mathbb{E}(Y_n)\). In our problem, can we just directly apply the DCT?
Well, we would like to say that, for small but non-zero \(t\),
\[\mathbb{E}\left(\lim_{n \to \infty}\sum_{k=0}^n
\frac{t^k}{k!}(X-\mu)^k\right) = \lim_{n \to
\infty}\mathbb{E}\left(\sum_{k=0}^n \frac{t^k}{k!}(X-\mu)^k\right),\]
i.e., \(Y_n = \sum_{k=0}^n \frac{t^k}{k!}(X-\mu)^k\) and \(Y =
e^{t(X-\mu)}\). But what should be the dominating variable \(Z\)? We can
easily see that \(Y_n \leq \sum_{k=0}^n \frac{|t|^n}{n!} |X-\mu|^n \leq
e^{|t| |X-\mu|}\), but do we know that the latter is integrable? It
wasn&rsquo;t obvious to me, so let&rsquo;s dive into the details.</p>
<h2 id="facts-about-moment-generating-functions">Facts about moment generating functions</h2>
<p>Let \(X\) be a random variable, and define \(\Psi_X(t) =
\mathbb{E}(e^{tX})\), for \(t \in D\), where \(D = \{t \in \mathbb{R}:
\mathbb{E}(e^{tX}) &lt; \infty\}\). Note that \(e^{tX} \geq 0\), so that its
expectation is always well-defined in \([0, \infty]\). Moreover, \(0 \in
D\) no matter what, as \(\mathbb{E}(e^{0X}) = 1 &lt; \infty\) &mdash; this could
<a href="https://en.wikipedia.org/wiki/Cauchy_distribution" target="_blank" rel="noopener noreffer ">possibly</a> be the only element of \(D\). The first interesting fact about
\(\Psi_X\) is that its domain \(D\) is always an interval including zero.</p>
<p><strong>Lemma 1</strong>: If \(t \in D \cap (0, \infty)\), then \([0, t] \subseteq
D\). Similarly, if \(t \in D \cap (-\infty, 0)\), then \([t, 0] \subseteq
D\).</p>
<p><em>Proof</em>: Suppose \(t &gt; 0\), \(\mathbb{E}(e^{tX}) &lt; \infty\), and let \(s
\in [0, t]\). Observe that \[\mathbb{E}(e^{sX}) = \mathbb{E}(e^{sX}
\mathbf{1}_{[0, \infty)}(X)) + \mathbb{E}(e^{sX} \mathbf{1}_{(-\infty,
0)}(X)) \leq \mathbb{E}(e^{tX} \mathbf{1}_{[0,\infty)}) + P[X &lt; 0]
\leq \Psi_{X}(t) + 1 &lt; \infty,\] so \(s \in D\). Similarly, if \(t &lt; 0\),
\(\mathbb{E}(e^{tX}) &lt; \infty\), then let \(s \in [t, 0]\) and note that
\[\mathbb{E}(e^{sX}) = \mathbb{E}(e^{sX} \mathbf{1}_{(0,
\infty)}(X)) + \mathbb{E}(e^{sX} \mathbf{1}_{(-\infty, 0]}(X)) \leq
P[X &gt; 0] + \mathbb{E}(e^{tX} \mathbf{1}_{(-\infty, 0]}(X)) \leq 1 +
\Psi_X(t),\] so \(s \in D\). \(\quad \blacksquare\)</p>
<br />
MGFs are useful when they exist on an open interval around zero — it
is in this case that they actually generate moments! This is
formalized in the next result.
<p><strong>Proposition 1</strong>: Suppose \(t^* &gt; 0\) is such that \((-t^*, t^*) \subseteq
D\). Then \(\mathbb{E}(|X|^n) &lt; \infty\), for all \(n \in \mathbb{N}\),
\[\Psi_X(t) = \sum_{n = 0}^\infty \frac{t^n}{n!} \mathbb{E}(X^n)\]
holds and this series is absolutely convergent, for all \(t \in
(-t^*, t^*)\). Consequently, \(\mathbb{E}(X^n) = \left. \frac{d^n}{dt^n}
\Psi_X(t) \right|_{t = 0}\).</p>
<p><em>Proof</em>: Let \(t \in (0, t^*)\). The key observation is that \(e^{t|x|}
\leq e^{-tx} + e^{tx}\), for all \(x \in \mathbb{R}\). Thus,
\[\mathbb{E}(e^{t|X|}) \leq \Psi_X(-t) + \Psi_X(t) &lt; \infty,\] given
that \(-t, t \in D\). In other words, by the power series expansion of
the exponential, \[\mathbb{E}(e^{t|X|}) =
\mathbb{E}\left(\sum_{n=0}^{\infty} \frac{t^n}{n!} |X|^n\right) =
\sum_{n=0}^{\infty} \frac{t^n}{n!}  \mathbb{E}(|X|^n) &lt; \infty,\]
where the interchange of expectation and summation is permitted by the
monotone convergence theorem (MCT). Immediately, we can deduce that
\(\mathbb{E}(|X|^n) &lt; \infty\) for all \(n \in \mathbb{N}\). We further
can see by the DCT that \(\Psi_X(t) = \sum_{n=0}^\infty \frac{t^n}{n!}
\mathbb{E}(X^n)\) for any \(t \in (-t^*, t^*)\), as the partial sums
\(\sum_{k=0}^N \frac{t^n}{n!}  X^n\), for \(N \in \mathbb{N}\), are
uniformly bounded by \(e^{|t| \cdot |X|} \in L_1\).</p>
<p>Notice that we have shown that the power series \(\sum_{n=0}^{\infty}
\frac{t^n}{n!} \mathbb{E}(X^n)\) converges absolutely on \((-t^*, t^*)\),
i.e., its <a href="https://en.wikipedia.org/wiki/Radius_of_convergence" target="_blank" rel="noopener noreffer ">radius of convergence</a> is at least \(t^*\). By basic facts
about power series, \(\Psi_X(t)\) is infinitely differentiable on
\((-t^*, t^*)\), and \(\mathbb{E}(X^n) = \left. \frac{d^n}{dt^n}
\Psi_X(t) \right|_{t = 0}\). \(\quad \blacksquare\) <br />
<br />
Inspecting the proof of Proposition 1, we can see that the real power
(no pun intended) comes from \(e^{|tX|}\) being integrable. The crux of
the argument was that \(\{-t, t\} \subseteq D\) is equivalent to
\(\mathbb{E}(e^{|tX|}) &lt; \infty\), and the latter readily establishes
that \(\Psi_X\) permits the power series representation \(\Psi_X(s) =
\sum_{n=0}^\infty \frac{s^n}{n!}\mathbb{E}(X^n)\), for \(s \in \{-t,
t\}\). With Lemma 1, we pretty much immediately obtain the following
nice chain of equivalences.</p>
<p><strong>Theorem</strong>: <em>For any</em> \(t \in \mathbb{R}\):</p>
<p>\begin{align*}
&amp;\{-t, t\} \subseteq D \text{ (or say } [-|t|, |t|]
\subseteq D \text{ if you like)}\\
\iff &amp;\mathbb{E}(e^{|sX|}) &lt; \infty, \textit{for all } s \in
[-|t|, |t|] \\
\iff &amp;\sum_{n=0}^\infty \frac{t^n}{n!} \mathbb{E}(X^n)
\textit{ absolutely converges and equals } \Psi_X(t)
\textit{ for } t \in [-|t|, |t|]
\end{align*}</p>
<p>[Notice that this is useful only when \(t \neq 0\).]</p>
<h2 id="relation-to-sub-exponential-distributions">Relation to sub-exponential distributions</h2>
<p>At this point, we are equipped to understand a more general version of
the problem we started out with (<strong>side note: are the necessary facts
about MGFs just supposed to be common knowledge!?</strong>). Namely, we will
verify that \(X\) is sub-exponential if and only if the domain \(D\) of
\(\Psi_X\) contains an open interval around zero [for those reading the
Wainwright text, this is part of Theorem 2.13]. Clearly, if \(\nu &gt; 0\)
and \(\alpha \in [0,\infty)\) satisfy \(\mathbb{E}(e^{t(X-\mu)}) \leq
e^{\frac{\nu^2 t^2}{2}}\) (notice in particular that this is finite)
for \(t \in (-\alpha^{-1}, \alpha^{-1})\), then \(D\) contains any pair
\(\{-t, t\}\) for \(t \in (0, \alpha^{-1})\), and we see that
\((-\alpha^{-1}, \alpha^{-1}) \subseteq D\). The following says that the
converse result also holds.</p>
<p><strong>Proposition 2</strong>: <em>The MGF of</em> \(X\) <em>is defined on</em> \(D \supseteq (-c,
c)\) <em>for some</em> \(c &gt; 0\) <em>if and only if</em> \(X\) <em>is sub-exponential</em>.</p>
<p><em>Proof</em>: We have just argued in the &ldquo;if&rdquo; direction. For the converse,
suppose \(c &gt; 0\) and \((-c,c) \subseteq D\). By our theorem, it is kosher
to use the power series expansion of \(\Psi_{X - \mu}(t)\) for any \(t
\in (-c,c)\) &mdash; note by the way that the domain \(D\) of \(\Psi_X\) is
equal to that of the MGF of the centered variable \(\Psi_{X - \mu}\), as
they differ by a deterministic finite multiplicative factor
\(e^{-t\mu}\). Further, as the radius of convergence of this power
series is at least \(c\), we can differentiate term by term on \((-c,c)\)
to obtain the derivative of \(\Psi_{X - \mu}\). Consequently, by
Taylor&rsquo;s theorem with Peano remainder, \[\Psi_{X - \mu}(t) =
\Psi_{X-\mu}(0) + \Psi^{(1)}_{X - \mu}(0)t + \frac{\Psi^{(2)}_{X -
\mu}(0)}{2}t^2 + o(t^2) = 1 + \frac{\sigma^2 t^2}{2} + o(t^2), \text{
as } t \to 0,\] where \(\sigma^2 = \mathbb{E}[(X - \mu)^2]\); recall
that all moments are finite by Proposition 1. Similarly, for any
\(\nu &gt; 0\),</p>
<p>\begin{align*}
\exp{\left\{\frac{\nu^2 t^2}{2}\right\}}
&amp;=
\left[1 + \left\{\nu^2 s\exp{\left\{\frac{\nu^2
s^2}{2}\right\}}\right\} t + \frac{1}{2}
\left\{\nu^2 \exp{\left\{\frac{\nu^2
s^2}{2}\right\}}\left(1 + \nu^2 s^2\right)\right\}
t^2\right]_{s=0} + o(t^2) \\
&amp;= 1 + \frac{\nu^2 t^2}{2} + o(t^2), \text{ as } t \to 0,
\end{align*}</p>
<p>as \(e^x\) is smooth. Combining these facts, we obtain for any \(\nu &gt;
0\), \[\exp{\left\{\frac{\nu^2 t^2}{2}\right\}} - \mathbb{E}(e^{t(X -
\mu)}) = \frac{t^2}{2}(\nu^2 - \sigma^2)+ o(t^2), \text{ as } t \to
0.\] To make sure this exceeds zero, at least for small \(t\), we will
choose an arbitrary \(\nu &gt; \sigma\). Meanwhile, choose \(\delta &gt; 0\)
such that whenever \(|t| &lt; \delta\), \[\left|\frac{1}{t^2}\left(
\exp{\left\{\frac{\nu^2 t^2}{2}\right\}} - \mathbb{E}(e^{t(X -
\mu)})\right) - \frac{\nu^2 - \sigma^2}{2}\right| &lt; \epsilon,\] where
we choose \(\epsilon = \frac{\nu^2 - \sigma^2}{4} &gt; 0\). We then can see
that \[\epsilon t^2 + \mathbb{E}(e^{t(X - \mu)}) \leq
\exp{\left\{\frac{\nu^2 t^2}{2}\right\}} \text{ for all } t \in
(-\delta, \delta),\] so \(X\) is $(ν,
\frac{1}{\delta})$-sub-exponential. \(\quad \blacksquare\)</p>
<h2 id="control-of-the-moments-and-bernstein-s-condition">Control of the moments and Bernstein&rsquo;s condition</h2>
<p>Viewing the formula for the MGF as a power series, we can obtain one
more useful characterization of its existence in an open interval
around zero.</p>
<p><strong>Proposition 3</strong>: <em>The MGF of</em> \(X\) <em>is defined on</em> \(D \supseteq (-c,
c)\) <em>for some</em> \(c &gt; 0\), <em>if and only if</em> \[\gamma \coloneqq \limsup_{n
\to \infty} \left(\frac{\left|\mathbb{E}(X^n)\right|}{n!}\right)^{1/n}
&lt; \infty.\]</p>
<p><em>Proof</em>: By our theorem, \((-c, c) \subseteq D\) for some \(c &gt; 0\) if and
only if \(X^n \in L_1\) for all \(n \in \mathbb{N}\) and the radius of
convergence \(R\) of the power series \(\sum_{n=0}^\infty \frac{t^n}{n!}
\mathbb{E}(X^n)\) is positive. But \(R = \frac{1}{\gamma}\) by <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Hadamard_theorem" target="_blank" rel="noopener noreffer ">standard
power series facts</a>, so we conclude that \(R &gt; 0\) if and only if \(\gamma
&lt; \infty\). \(\quad \blacksquare\) <br />
<br />
With this result in hand, we can more easily see that the Bernstein
condition implies the sub-exponential property. Indeed, if \(X\) is
$b$-Bernstein for some \(b &gt; 0\), then \[\limsup_{n \to \infty}
\left(\frac{\left|\mathbb{E}[(X - \mu)^n]\right|}{n!}\right)^{1/n}
\leq b \limsup_{n \to \infty} \left(\frac{\sigma^2}{2b^2}\right)^{1/n}
= b &lt; \infty.\] Thus, \(\left(-\frac{1}{b}, \frac{1}{b}\right)
\subseteq D\), again using that the domains of \(\Psi_X\) and \(\Psi_{X -
\mu}\) are both \(D\). By Proposition 2, we are done!</p>
<h2 id="bonus-a-direct-analysis-of-the-bernstein-condition">BONUS: A direct analysis of the Bernstein condition</h2>
<p>In talking through this with some peers at CMU, I learned (thanks to
<a href="https://www.cmu.edu/dietrich/statistics-datascience/people/phd/zhenghao-zeng.html" target="_blank" rel="noopener noreffer ">Tiger Zeng</a>) that we could also directly verify that the Bernstein
condition implies \(\mathbb{E}(e^{|tX|}) &lt; \infty\) for \(t \in
\left(-\frac{1}{b}, \frac{1}{b}\right)\). At that point we could just
use the DCT to justify the interchange of expectation and sum. Since
the idea was pretty clever, I&rsquo;ve decided to write it out here.</p>
<p>Suppose \(X\) is $b$-Bernstein for \(b &gt; 0\). We wish to show that
\(\mathbb{E}(e^{|t| \cdot |X-\mu|}) &lt; \infty\) for any \(t \in
\left(-\frac{1}{b}, \frac{1}{b}\right)\), and recall that by the Taylor
series for \(e^x\) and the MCT, this expectation always equals
\(\sum_{n=0}^{\infty} \frac{|t|^n}{n!}\mathbb{E}(|X-\mu|^n)\). The
difficulty comes from the fact that the Bernstein condition does not
speak directly to \(\mathbb{E}(|X-\mu|^n)\), but rather to
\(\left|\mathbb{E}[(X-\mu)^n]\right|\). For \(n\) even, these coincide,
but for \(n\) odd, some care is needed.</p>
<p>Explicitly separating the even and odd terms, we have
\[\mathbb{E}(e^{|t| \cdot |X-\mu|}) = \sum_{k=0}^\infty
\frac{|t|^{2k}}{(2k)!}\mathbb{E}(|X-\mu|^{2k}) + \sum_{k=0}^\infty
\frac{|t|^{2k + 1}}{(2k + 1)!}\mathbb{E}(|X-\mu|^{2k + 1}).\] We show
these sums are both finite in turn. Starting with the even terms,
since \(X\) is $b$-Bernstein, \[\sum_{k=0}^\infty
\frac{t^{2k}}{(2k)!}\mathbb{E}[(X-\mu)^{2k}] = 1 + \sum_{k=1}^\infty
\frac{t^{2k}}{(2k)!}\mathbb{E}[(X-\mu)^{2k}] \leq 1 +
\frac{\sigma^2}{2} \sum_{k=1}^{\infty}t^{2k}b^{2k - 2} = 1 +
\frac{\sigma^2 t^2 / 2}{1 - t^2b^2},\] by summing the geometric
series, noting that \(t^2 b^2 = (|t|b)^2 &lt; 1\) by assumption. For the
odd terms, the trick is to forcefully introduce even moments using
Cauchy-Schwarz: for any \(k \in \mathbb{N}\), \[\mathbb{E}(|X-\mu|^{2k +
1}) = \mathbb{E}(|X - \mu|^{k + 1} |X - \mu|^k) \leq
\left\{\mathbb{E}[(X - \mu)^{2k + 2}]\mathbb{E}[(X -
\mu)^{2k}]\right\}^{1/2},\] by Cauchy-Schwarz. Thus, as \(X\) is
$b$-Bernstein, \[\mathbb{E}(|X-\mu|^{2k + 1}) \leq \frac{\sigma^2
b^{2k-1}}{2} \sqrt{(2k)! (2k+2)!} \leq (2k + 1)! \sigma^2 b^{2k -
1},\] since \(\sqrt{(2k)! (2k+2)!} = (2k + 1)! \sqrt{\frac{2k+2}{2k +
1}} &lt; 2 (2k+1)!\) for all \(k \in \mathbb{N}\). Therefore,
\[\sum_{k=0}^\infty
\frac{|t|^{2k+1}}{(2k+1)!}\mathbb{E}(|X-\mu|^{2k+1}) \leq
\mathbb{E}(|X - \mu|) + \sigma^2\sum_{k=1}^{\infty}|t|^{2k+1}b^{2k-1}
= \mathbb{E}(|X - \mu|) + \frac{b \sigma^2 |t|^3}{1 - |t|b}.\] Putting
everything together, we have \(\mathbb{E}(e^{|t| \cdot |X-\mu|}) &lt;
\infty\). Phew!</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-08-05</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://alexlevis.github.io/mgf-bounds/"><i class="fab fa-linkedin fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav">
            <a href="/instrument-precision/" class="next" rel="next" title="To adjust or not to adjust: instruments and precision variables">To adjust or not to adjust: instruments and precision variables<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.127.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2019 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Alex Levis</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
